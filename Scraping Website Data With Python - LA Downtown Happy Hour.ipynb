{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import gzip\n",
    "import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect html from the happy hour website of downtownla\n",
    "url = \"https://www.downtownla.com/explore/dining-nightlife/happy-hour-finder\"\n",
    "resource = urllib2.urlopen(url).read()\n",
    "resource = StringIO.StringIO(resource) \n",
    "#decomposing the html file and turn it into a big string then turn into BeautifulSoup\n",
    "source = str()\n",
    "for data in gzip.GzipFile(fileobj=resource):\n",
    "    source=source+data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse data\n",
    "tables = BeautifulSoup(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scraper found 98 happy hours\n"
     ]
    }
   ],
   "source": [
    "# get the restauratnt with happy hour\n",
    "restaurant = []\n",
    "res =  tables.findAll(\"h3\",{'class':'location'})\n",
    "for t in res:\n",
    "        restaurant.append(t.text[2:])\n",
    "print \"The scraper found %d happy hours\" % len(restaurant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 3 of them, yeah!\n",
      "[u\"Casey's Irish Pub, Deals on appetizers, burgers, and Guinness\", u'Takami Sushi & Robata Restaurant, Delicious hand-crafted cocktails, imported beers, full sake, wine, and liquor menu, sushi and Robata sampler plates, light bites-- all...', u'Ebisu Japanese Tavern, Deals on drinks, appetizers, and sushi rolls from 11:30-2:30, 5:30-7:00, and 10:30-midnight.']\n"
     ]
    }
   ],
   "source": [
    "# go through the food I like \n",
    "# and see if any happy hour descritionps match \n",
    "food_i_like = ['burger', 'bear', 'sushi', 'sweet potato fries']\n",
    "happy_hour=[]\n",
    "my_happy_hour = []\n",
    "detail = tables.findAll(\"p\")[2:100] \n",
    "# combine the restaurant name and their description\n",
    "for i in range(98):\n",
    "    happy_hour.append(restaurant[i] + \", \" + detail[i].text)\n",
    "for food in food_i_like:\n",
    "    for hh in happy_hour:\n",
    "        if food in hh and hh not in my_happy_hour:\n",
    "            my_happy_hour.append(hh)\n",
    "print 'I found %d of them, yeah!' % len(my_happy_hour)\n",
    "print my_happy_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, Xiaoyan,\n",
      "\n",
      "\n",
      "OMG, I found some stuff in Downtown LA, take a look.\n",
      "\n",
      "Casey's Irish Pub, Deals on appetizers, burgers, and Guinness=========================\n",
      "Takami Sushi & Robata Restaurant, Delicious hand-crafted cocktails, imported beers, full sake, wine, and liquor menu, sushi and Robata sampler plates, light bites-- all...=========================\n",
      "Ebisu Japanese Tavern, Deals on drinks, appetizers, and sushi rolls from 11:30-2:30, 5:30-7:00, and 10:30-midnight.\n",
      "\n",
      "XOXO,\n",
      " Your Py Script\n"
     ]
    }
   ],
   "source": [
    "# make a mail message that we can read:\n",
    "message = 'Hey, Xiaoyan,\\n\\n\\n'\n",
    "message += 'OMG, I found some stuff in Downtown LA, take a look.\\n\\n'\n",
    "message += '=========================\\n'.join(my_happy_hour)\n",
    "message = message.encode('utf-8')\n",
    "message = message.replace('\\t', '').replace('\\r', '')\n",
    "message += '\\n\\nXOXO,\\n Your Py Script'\n",
    "print message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources Used:\n",
    "    Harvard CS109 Data Science\n",
    "    Katharine Jarmul: Introduction to Web (and data!) Scraping with Python - PyCon 2014 (https://www.youtube.com/watch?v=p1iX0uxM1w8&t=2129s)\n",
    "    Downtownla (https://www.downtownla.com/explore/dining-nightlife/happy-hour-finder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
